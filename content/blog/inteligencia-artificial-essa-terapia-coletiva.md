---
title: "Inteligência artificial, essa terapia coletiva"
date: "2021-04-22"
categories: 
  - "newsletter"
tags: 
  - "antropologia"
  - "capitalismo"
  - "claude-levi-strauss"
  - "clifford-geertz"
  - "cultura"
  - "google"
  - "inteligencia-artificial"
  - "politica"
  - "tecnologia"
  - "tim-harford"
---

Às vezes, as notícias sobre Inteligência Artificial são um tanto engraçadas. Por exemplo, [as ferramentas do Google, perdidas na tradução](https://www.reuters.com/technology/google-translation-ai-botches-legal-terms-enjoin-garnish-research-2021-04-19/), confundindo termos jurídicos e palavras fora do contexto. "Ah, [esses humanos](https://www.youtube.com/watch?v=6Lm-ZsZcsMs)… Eu não aguento, eles usam as mesmas palavras pra dizer coisas opostas!"

Aqui estamos nós, empreendedores e pesquisadores, tentando ensinar máquinas a resolver problemas que não sabemos solucionar. Percebendo nossa ingenuidade, já que as coisas aparentemente mais simples são, na verdade, muito complicadas. Em especial politicamente. Ao programar algo que chamamos de inteligência, nos descobrimos um tanto burros. Faz parte.

Algumas coisas ficam vergonhosamente claras. Por exemplo: não é por acaso que, há milhares de anos, debatemos o que, afinal, é inteligência, de onde ela vem, quais são os seus limites e preconceitos. Humanos não se resolvem a golpes de neurociência e encadeamentos lógicos. Literatura, psicologia, filosofia, antropologia, economia etc., não surgiram porque os humanos estavam entediados, sem sinal de Internet.

Há uma gigantesca cadeia de complexidades envolvidas até mesmo no ato de levantar um cascalho do chão. Manejamos da gravidade até as posturas físicas, que aprendemos dos padrões culturais da nossa época. E esse "aprendizado profundo" nunca acaba.

Podemos tentar ignorar esse fato: "ah, o importante é reconhecer aquele rosto e criar uma propaganda adequada". Mas, como os programadores já sabem (e o público em geral está começando a entender), **o próprio processo de construir a inteligência artificial é um tipo de autoconhecimento**.

Descobrimos que não sabemos como _muitas_ coisas funcionam. Nem mesmo quais são suas implicações sociais e ambientais. Ainda assim, somos capazes de arriscar, criar e produzir resultados. É a nossa maior "feature" e, ao mesmo tempo, nosso maior "bug".

Portanto, é claro que surgirão novos produtos, que as máquinas serão capazes de realizar cada vez mais atividades. Mas nem sempre conseguiremos entender completamente como. E elas também criarão necessidades inesperadas.

A construção da inteligência artificial é também uma terapia coletiva. É que, ao trabalhar pra criar máquinas que sejam eficientes e rápidas, descobrimos o quanto somos dominados por esses conceitos nos últimos 500 anos.

E, quando as máquinas não conseguem atingir nossas expectativas, notamos como esses mesmos valores são vagos, ideológicos e muitas vezes utópicos. Mesmo que venham baseados em mistificações e confusões estatísticas: "se é número, deve estar certo". O problema é que nem sempre sabemos interpretá-los (pelo menos segundo [Tim Harford](https://www.amazon.com.br/Data-Detective-Rules-Sense-Statistics/dp/0593084594?__mk_pt_BR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=tim+harford&qid=1618945473&sr=8-1&linkCode=ll1&tag=eduf-20&linkId=facb3be8c66c8dc3aae856ce7542b410&language=pt_BR&ref_=as_li_ss_tl)).

Esse é um fenômeno com o qual os programadores já estão bem familiarizados. Você investiga um erro, o código está certo, o computador fez exatamente aquilo que foi solicitado. O desenvolvedor é que não entendeu o problema, inicialmente. Formular corretamente a pergunta é o passo mais importante do projeto.

Criar inteligência artificial nos força a voltar pra questões fundamentais, [pensar sobre o que é a infância](https://www.nytimes.com/2021/04/16/podcasts/ezra-klein-podcast-alison-gopnik-transcript.html), política e cultura. E também sobre outros tipos de inteligência, fora da lógica iluminista e capitalista. O que é uma grande oportunidade, já que tendemos a nos esquecer da quantidade de culturas e de saberes que já dominaram este planeta e depois viraram artigos de museu. Saberes como os que o antropólogo Claude Lévi-Strauss [investigou há décadas, em O Pensamento Selvagem](https://www.amazon.com.br/Pensamento-Selvagem-Claude-L%C3%A9vi-Strauss/dp/8530800834?__mk_pt_BR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=o+pensamento+selvagem&qid=1618869976&sr=8-3&linkCode=ll1&tag=eduf-20&linkId=435a828dfbfedf7b2a84061e78222b42&language=pt_BR&ref_=as_li_ss_tl).

Aliás, hoje, os criadores de inteligência artificial passam por um processo, de alguma forma, parecido com o do nascimento da antropologia: ao estudar "o outro" (no caso, as máquinas), vemos o quanto somos racistas e enviesados. Assim como os primeiros etnógrafos, também somos obrigados a aprender a ouvir e a observar (e será que vamos coletar [histórias tão boas quanto as de Clifford Geertz](https://www.amazon.com.br/Interpreta%C3%A7%C3%A3o-das-Culturas-Clifford-Geertz/dp/8521613334?__mk_pt_BR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&dchild=1&keywords=Clifford+Geertz&qid=1618870113&sr=8-1&linkCode=ll1&tag=eduf-20&linkId=de95e95509f1aa985f906d483efde2fe&language=pt_BR&ref_=as_li_ss_tl)?)

Politicamente, a inteligência artificial pode se tornar, por um lado, a consumação do sonho da sociedade de controle. Por outro, a própria decadência desta, pois, ao tentar aumentar cada vez mais a sua eficiência, descobrirá (e denunciará involuntariamente) os limites da própria ideia de eficiência.

Tudo isso pra dizer o seguinte: não estamos criando A inteligência artificial. Mas UM determinado tipo, muito limitado, de fenômeno cultural, a Inteligência Artificial Capitalista.

Por enquanto.
