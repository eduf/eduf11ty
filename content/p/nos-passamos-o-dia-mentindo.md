---
title: "Nós passamos o dia mentindo"
date: "2023-10-17"
tags: 
  - "newsletter"
  - "bard"
  - "chatgpt"
  - "inteligencia-artificial"
  - "pos-verdade"
---

Você chega a uma reunião. Nota um rosto conhecido. A pessoa te cumprimenta, animadamente. Parece saber detalhes sobre sua vida. Mas você não consegue se lembrar de onde a conhece.

A interlocutora vai se expandindo. Agora seria totalmente rude pará-la e perguntar: “quem é você mesmo?”

O que você faz? Ora, vai enrolando e fazendo perguntas estratégicas pra tentar conseguir mais informações. Pelo menos, as suficientes pra evitar uma gafe.

Seu cérebro passa por um frenesi classificatório: a cada interação, testa uma hipótese sobre a pessoa, descarta outras e deduz uma continuação segura pra conversa.

É um Tetris cognitivo. Ou mais ou menos como uma dessas caixas de busca com a função _autocomplete_.

A pessoa te pergunta: “Lembra daquela situação?” Você diz que sim, mas está mais perdido do que o sujeito do filme [Memento](https://pt.wikipedia.org/wiki/Memento_(filme)). Neste ponto, a sua porcentagem de mentiras brancas já está nos 60 ou 70%. Não só nas palavras, mas até nas expressões.

Você nem está participando da conversa, realmente. Resolve um quebra-cabeça e tenta não passar vergonha. Ou acha um jeito de consertar as incoerências que vão aparecendo nas suas respostas. Só quer evitar ser pego.

Enfim. Se isso acontece com humanos, por que não com a Inteligência Artificial Generativa?

Outro dia, escrevendo um artigo, perguntei ao Bard, do Google, quantos funcionários trabalhavam numa determinada fábrica em 2011. Confiante, ele respondeu: “Nenhum. A fábrica não existia na época.”

Mas eu estava com um livro aberto à minha frente que contradizia essa informação. Publicado por um dos próprios gerentes da fábrica. Basicamente, o Bard estava contradizendo a própria existência da obra, escrita pra contar a história daquele local em 2011 e 2012.

Assim, eu tinha duas hipóteses:

1. Estou num universo paralelo.
2. O Bard alucinou.

Optei pela primeira, claro. Mas resolvi checar com o programa: “compare sua última afirmação com o livro X”.

E o Bard fez toda uma ginástica mental pra não passar vergonha. E se saiu com algo ainda mais constrangedor. Citou uma frase do texto e reafirmou: “portanto, conforme o livro, a informação está correta”.

Não, não estava.

Coisa mais humana, essa cara de pau. Melhor que teste de Turing pra diferenciar entre gente e inteligência artificial. Quase convidei o aplicativo pra tomar um pingado na padaria. Pra mim, já era um Bard da Silva ou Bard de Souza.

Mas, por curiosidade, fui ao ChatGPT. Este foi muito mais seco, mais europeu: “Não consegui encontrar dados suficientes pra dar uma informação correta sobre o assunto. Você pode ler o livro X para maiores detalhes”.

Agora sim.

Mas, se você encontrasse o Bard e o ChatGPT numa festa, quem acharia mais simpático? Pensando na quantidade de desinformação (bem ou mal intencionada) que temos de gerenciar diariamente, é possível que preferisse o primeiro. Ele mente, mas “resolve”.

Eu diria até que estamos muito mais habituados à mentira do que à verdade. Mentira é como _confort food_: parece que ajuda, mas mata.

Segundo a imprensa especializada, o Bard está mesmo numa fase de cambalear e derrubar pratos por aí. A ideia do Google é juntar quantidades gigantescas de _feedback_.

Não só pra corrigir o programa, mas pra entender como nos comportamos ao buscar coisas na Internet. E como lidamos com informação, mesmo as incorretas. É por isso que os sistemas de busca ainda são um dos maiores experimentos sociais já inventados.

O que parece claro até agora é que, definitivamente, nunca foi fácil ser sincero e verdadeiro. Dentro e fora dos ambientes digitais.
